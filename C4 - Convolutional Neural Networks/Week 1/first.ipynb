{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.pad(test,((2,2),),mode='constant',constant_values=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 2, 3, 0, 0],\n",
       "       [0, 0, 4, 5, 6, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 7), (2, 3))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 1 line)\n",
    "\n",
    "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),mode='constant',constant_values=(0,0))\n",
    "\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 7, 7, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16d39243ca0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1,1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from A_prev's shape (â‰ˆ1 line)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape[0], A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]\n",
    "\n",
    "    (f, f, n_C_prev, n_C) = W.shape[0],W.shape[1],W.shape[2],W.shape[3]\n",
    "\n",
    "    stride,pad = hparameters['stride'],hparameters['pad']\n",
    "\n",
    "    n_H = int(((n_H_prev-f+2*pad)/stride)+1)\n",
    "\n",
    "    n_W = int(((n_W_prev-f+2*pad)/stride)+1)\n",
    "\n",
    "    Z = np.zeros([m, n_H, n_W, n_C])\n",
    "\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    \n",
    "    for i in range(m):                  # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]      # Select ith training example's padded activation\n",
    "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (â‰ˆ2 lines)\n",
    "            vert_start = stride * h\n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (â‰ˆ2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (â‰ˆ1 line)\n",
    "                    a_slice_prev = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (â‰ˆ3 line)\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "                                        \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.6923608807576933\n",
      "Z[3,2,1] =\n",
      " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
      " 13.00689405  2.34576051]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,5,7,4)\n",
    "W = np.random.randn(3,3,4,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (â‰ˆ2 lines)\n",
    "            vert_start = stride * h \n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (â‰ˆ2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (â‰ˆ1 line)\n",
    "                    a_prev_slice = A_prev[i]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c])\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c])\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[1.74481176 0.90159072 1.65980218]\n",
      "   [1.74481176 1.46210794 1.65980218]\n",
      "   [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.14472371 0.90159072 2.10025514]\n",
      "   [1.14472371 0.90159072 1.65980218]\n",
      "   [1.14472371 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 0.84616065 0.82797464]\n",
      "   [0.69803203 0.84616065 1.2245077 ]\n",
      "   [0.69803203 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.84616065 1.27375593]\n",
      "   [1.96710175 0.84616065 1.23616403]\n",
      "   [1.62765075 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.86888616 1.27375593]\n",
      "   [1.96710175 0.86888616 1.23616403]\n",
      "   [1.62765075 1.12141771 0.79280687]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[-3.01046719e-02 -3.24021315e-03 -3.36298859e-01]\n",
      "   [ 1.43310483e-01  1.93146751e-01 -4.44905196e-01]\n",
      "   [ 1.28934436e-01  2.22428468e-01  1.25067597e-01]]\n",
      "\n",
      "  [[-3.81801899e-01  1.59993515e-02  1.70562706e-01]\n",
      "   [ 4.73707165e-02  2.59244658e-02  9.20338402e-02]\n",
      "   [ 3.97048605e-02  1.57189094e-01  3.45302489e-01]]\n",
      "\n",
      "  [[-3.82680519e-01  2.32579951e-01  6.25997903e-01]\n",
      "   [-2.47157416e-01 -3.48524998e-04  3.50539717e-01]\n",
      "   [-9.52551510e-02  2.68511000e-01  4.66056368e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.73134159e-01  3.23771981e-01 -3.43175716e-01]\n",
      "   [ 3.80634669e-02  7.26706274e-02 -2.30268958e-01]\n",
      "   [ 2.03009393e-02  1.41414785e-01 -1.23158476e-02]]\n",
      "\n",
      "  [[ 4.44976963e-01 -2.61694592e-03 -3.10403073e-01]\n",
      "   [ 5.08114737e-01 -2.34937338e-01 -2.39611830e-01]\n",
      "   [ 1.18726772e-01  1.72552294e-01 -2.21121966e-01]]\n",
      "\n",
      "  [[ 4.29449255e-01  8.44699612e-02 -2.72909051e-01]\n",
      "   [ 6.76351685e-01 -1.20138225e-01 -2.44076712e-01]\n",
      "   [ 1.50774518e-01  2.89111751e-01  1.23238536e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stride': 1, 'f': 3}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A =\n",
      " [[[[1.74481176 0.90159072 1.65980218]\n",
      "   [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 0.84616065 0.82797464]\n",
      "   [0.69803203 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.86888616 1.27375593]\n",
      "   [1.62765075 1.12141771 0.79280687]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A =\n",
      " [[[[-0.03010467 -0.00324021 -0.33629886]\n",
      "   [ 0.12893444  0.22242847  0.1250676 ]]\n",
      "\n",
      "  [[-0.38268052  0.23257995  0.6259979 ]\n",
      "   [-0.09525515  0.268511    0.46605637]]]\n",
      "\n",
      "\n",
      " [[[-0.17313416  0.32377198 -0.34317572]\n",
      "   [ 0.02030094  0.14141479 -0.01231585]]\n",
      "\n",
      "  [[ 0.42944926  0.08446996 -0.27290905]\n",
      "   [ 0.15077452  0.28911175  0.00123239]]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 2: stride of 2\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "903d28fc8095cdeaee5be616f3ebb92fafee475741240b3f05159e4f3ac8bf72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
